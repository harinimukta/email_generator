{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eccd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16ff50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neil Armstrong.  He stepped onto the moon's surface on July 20, 1969, during the Apollo 11 mission.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    groq_api_key='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', \n",
    "    model_name=\"llama-3.1-70b-versatile\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"The first person to land on moon was ...\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d33612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Search JobsSkip navigationSearch JobsNIKE, INC. JOBSContract JobsJoin The Talent CommunityLife @ NikeOverviewBenefitsBrandsOverviewJordanConverseTeamsOverviewAdministrative SupportAdvanced InnovationAir Manufacturing InnovationAviationCommunicationsCustomer ServiceDesignDigitalFacilitiesFinance & AccountingGovernment & Public AffairsHuman ResourcesInsights & AnalyticsLegalManufacturing & EngineeringMarketingMerchandisingPlanningPrivacyProcurementProduct Creation, Development & ManagementRetail CorporateRetail StoresSalesSocial & Community ImpactSports MarketingStrategic PlanningSupply Chain, Distribution & LogisticsSustainabilityTechnologyLocationsOverviewNike WHQNike New York HQEHQ: Hilversum, The NetherlandsELC: Laakdal, BelgiumGreater China HQDiversity, Equity & InclusionOverviewMilitary InclusionDisability InclusionIndigenous InclusionInternshipsGIFT CARDSPROMOTIONSFIND A STORESIGN UP FOR EMAILBECOME A MEMBERNIKE JOURNALSEND US FEEDBACKGET HELPGET HELPOrder StatusShipping and DeliveryReturnsPayment OptionsGift Cards BalanceContact UsABOUT NIKEABOUT NIKENewsCareersInvestorsPurposeSustainabilityUnited StatesÂ© 2024 Nike, Inc. All Rights ReservedGuidesNike AdaptNike Air MaxNike FlyleatherNike ReactSpace HippieNike AirNike FlyEaseNike Free Nike VaporflyNike Air Force 1 Nike FlyknitNike JoyrideNike ZoomXTerms of SaleTerms of UseNike Privacy PolicyYour Privacy ChoicesCA Supply Chain Act\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://jobs.nike.com/job/R-33460\")\n",
    "page_data = loader.load().pop().page_content\n",
    "print(page_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c89a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'page_data':page_data})\n",
    "type(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5415fd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(res.content)\n",
    "json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39961ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8a0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tech Stack / Skills</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python, pandas, NumPy</td>\n",
       "      <td>https://chloemawer.github.io/portfolio.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning, Scikit-learn, XGBoost</td>\n",
       "      <td>https://machinelearningmastery.com/blog/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deep Learning, TensorFlow, Keras</td>\n",
       "      <td>https://aakashns.me/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natural Language Processing (NLP), spaCy, NLTK</td>\n",
       "      <td>https://sayannag.com/blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computer Vision, OpenCV, YOLO</td>\n",
       "      <td>https://www.pyimagesearch.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Visualization, Matplotlib, Seaborn</td>\n",
       "      <td>http://www.storytellingwithdata.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Big Data, Hadoop, Spark</td>\n",
       "      <td>https://github.com/dipanjanS/data_science_port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AI, Reinforcement Learning, PyTorch</td>\n",
       "      <td>https://yann.lecun.com/ex/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Time Series Analysis, ARIMA, Prophet</td>\n",
       "      <td>https://kausinis.github.io/TimeSeriesAnalysisP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Predictive Modeling, Random Forest, LightGBM</td>\n",
       "      <td>https://krzysztofrusiak.github.io/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Engineering, Airflow, Apache Kafka</td>\n",
       "      <td>https://www.pluralsight.com/authors/andreas-kretz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cloud ML, AWS SageMaker, Azure ML</td>\n",
       "      <td>https://github.com/aws-samples/amazon-sagemake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Science, R, ggplot2</td>\n",
       "      <td>http://varianceexplained.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AI Ethics, Explainable AI, SHAP</td>\n",
       "      <td>http://www.fast.ai/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Feature Engineering, Feature Selection, PCA</td>\n",
       "      <td>https://github.com/robmulla/feature_engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Model Deployment, Flask, FastAPI</td>\n",
       "      <td>https://sverma88.github.io/portfolio/deploying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AI in Healthcare, TensorFlow, Medical Imaging</td>\n",
       "      <td>https://josephpcohen.com/w/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Recommendation Systems, Collaborative Filtering</td>\n",
       "      <td>https://github.com/nikosari/recommendation-sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Autonomous Systems, Robotics, ROS</td>\n",
       "      <td>https://www.garciaruiz.org/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Cleaning, SQL, PySpark</td>\n",
       "      <td>https://github.com/alexvarlamov/data_cleaning_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Reinforcement Learning, OpenAI Gym, DQN</td>\n",
       "      <td>https://gym.openai.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLOps, Docker, Kubernetes</td>\n",
       "      <td>https://hamelsmu.github.io/mlops/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Transfer Learning, BERT, GPT</td>\n",
       "      <td>https://ruder.io/transfer-learning/index.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Wrangling, pandas, Dask</td>\n",
       "      <td>https://www.kaggle.com/dean-de-cock/titanic/data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Speech Recognition, Wav2Vec, Kaldi</td>\n",
       "      <td>https://voice.mozilla.org/en/datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Graph Neural Networks, DGL, PyTorch Geometric</td>\n",
       "      <td>https://github.com/rusty1s/pytorch_geometric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Anomaly Detection, Isolation Forest, Autoencoder</td>\n",
       "      <td>https://github.com/mgoetz/awesome-anomaly-dete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Edge AI, TensorFlow Lite, ONNX</td>\n",
       "      <td>https://www.tensorflow.org/lite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bayesian Statistics, PyMC3, Stan</td>\n",
       "      <td>https://github.com/fonnesbeck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Tech Stack / Skills  \\\n",
       "0                              Python, pandas, NumPy   \n",
       "1            Machine Learning, Scikit-learn, XGBoost   \n",
       "2                   Deep Learning, TensorFlow, Keras   \n",
       "3     Natural Language Processing (NLP), spaCy, NLTK   \n",
       "4                      Computer Vision, OpenCV, YOLO   \n",
       "5            Data Visualization, Matplotlib, Seaborn   \n",
       "6                            Big Data, Hadoop, Spark   \n",
       "7                AI, Reinforcement Learning, PyTorch   \n",
       "8               Time Series Analysis, ARIMA, Prophet   \n",
       "9       Predictive Modeling, Random Forest, LightGBM   \n",
       "10           Data Engineering, Airflow, Apache Kafka   \n",
       "11                 Cloud ML, AWS SageMaker, Azure ML   \n",
       "12                          Data Science, R, ggplot2   \n",
       "13                   AI Ethics, Explainable AI, SHAP   \n",
       "14       Feature Engineering, Feature Selection, PCA   \n",
       "15                  Model Deployment, Flask, FastAPI   \n",
       "16     AI in Healthcare, TensorFlow, Medical Imaging   \n",
       "17   Recommendation Systems, Collaborative Filtering   \n",
       "18                 Autonomous Systems, Robotics, ROS   \n",
       "19                       Data Cleaning, SQL, PySpark   \n",
       "20           Reinforcement Learning, OpenAI Gym, DQN   \n",
       "21                         MLOps, Docker, Kubernetes   \n",
       "22                      Transfer Learning, BERT, GPT   \n",
       "23                      Data Wrangling, pandas, Dask   \n",
       "24                Speech Recognition, Wav2Vec, Kaldi   \n",
       "25     Graph Neural Networks, DGL, PyTorch Geometric   \n",
       "26  Anomaly Detection, Isolation Forest, Autoencoder   \n",
       "27                    Edge AI, TensorFlow Lite, ONNX   \n",
       "28                  Bayesian Statistics, PyMC3, Stan   \n",
       "\n",
       "                                                Links  \n",
       "0         https://chloemawer.github.io/portfolio.html  \n",
       "1            https://machinelearningmastery.com/blog/  \n",
       "2                                https://aakashns.me/  \n",
       "3                           https://sayannag.com/blog  \n",
       "4                      https://www.pyimagesearch.com/  \n",
       "5                http://www.storytellingwithdata.com/  \n",
       "6   https://github.com/dipanjanS/data_science_port...  \n",
       "7                          https://yann.lecun.com/ex/  \n",
       "8   https://kausinis.github.io/TimeSeriesAnalysisP...  \n",
       "9                  https://krzysztofrusiak.github.io/  \n",
       "10  https://www.pluralsight.com/authors/andreas-kretz  \n",
       "11  https://github.com/aws-samples/amazon-sagemake...  \n",
       "12                      http://varianceexplained.org/  \n",
       "13                                http://www.fast.ai/  \n",
       "14    https://github.com/robmulla/feature_engineering  \n",
       "15  https://sverma88.github.io/portfolio/deploying...  \n",
       "16                        https://josephpcohen.com/w/  \n",
       "17  https://github.com/nikosari/recommendation-sys...  \n",
       "18                        https://www.garciaruiz.org/  \n",
       "19  https://github.com/alexvarlamov/data_cleaning_...  \n",
       "20                            https://gym.openai.com/  \n",
       "21                  https://hamelsmu.github.io/mlops/  \n",
       "22      https://ruder.io/transfer-learning/index.html  \n",
       "23   https://www.kaggle.com/dean-de-cock/titanic/data  \n",
       "24              https://voice.mozilla.org/en/datasets  \n",
       "25       https://github.com/rusty1s/pytorch_geometric  \n",
       "26  https://github.com/mgoetz/awesome-anomaly-dete...  \n",
       "27                    https://www.tensorflow.org/lite  \n",
       "28                      https://github.com/fonnesbeck  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"app/resource/portfolio_data_science_ml_ai.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e888d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore')#persistant will help to store data in folder (in disk)\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")\n",
    "\n",
    "if not collection.count():\n",
    "    for _, row in df.iterrows():\n",
    "        collection.add(documents=row[\"Techstack\"],\n",
    "                       metadatas={\"links\": row[\"Links\"]},\n",
    "                       ids=[str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ad2fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://example.com/ml-python-portfolio'},\n",
       "  {'links': 'https://example.com/magento-portfolio'}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = collection.query(query_texts=[\"Experience in Data Science\"], n_results=2).get('metadatas', [])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bd36844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ccfd720",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "job = json_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d96c858",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mjob\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexperience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "job['experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64a97dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Unlock Efficiency and Scalability with AtliQ's AI & Software Solutions\n",
      "\n",
      "Dear [Client's Name],\n",
      "\n",
      "I came across your company and was impressed by the innovative work you're doing in [industry/field]. As a Business Development Executive at AtliQ, I'd like to introduce you to our expertise in AI and software consulting, which can help take your business to the next level.\n",
      "\n",
      "At AtliQ, we specialize in designing and implementing tailored solutions that streamline processes, reduce costs, and enhance overall efficiency. Our team of experts has a proven track record of empowering enterprises like yours with automated tools that drive scalability and growth.\n",
      "\n",
      "Our portfolio showcases our capabilities in:\n",
      "\n",
      "* Machine Learning and Python development: https://example.com/ml-python-portfolio\n",
      "* React and React Native development: https://example.com/react-portfolio and https://example.com/react-native-portfolio\n",
      "\n",
      "These solutions have helped our clients achieve significant improvements in their operations, and we're confident that we can do the same for you.\n",
      "\n",
      "Some of the benefits you can expect from partnering with AtliQ include:\n",
      "\n",
      "* Process optimization through automation\n",
      "* Cost reduction through efficient resource allocation\n",
      "* Enhanced scalability to support business growth\n",
      "* Improved overall efficiency and productivity\n",
      "\n",
      "If you're interested in learning more about how AtliQ can help your business thrive, I'd be happy to schedule a call to discuss further.\n",
      "\n",
      "Please let me know if you'd like to explore this opportunity, and I'll send over some available time slots.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Mohan\n",
      "Business Development Executive\n",
      "AtliQ\n"
     ]
    }
   ],
   "source": [
    "prompt_email = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are Mohan, a business development executive at AtliQ. AtliQ is an AI & Software Consulting company dedicated to facilitating\n",
    "        the seamless integration of business processes through automated tools. \n",
    "        Over our experience, we have empowered numerous enterprises with tailored solutions, fostering scalability, \n",
    "        process optimization, cost reduction, and heightened overall efficiency. \n",
    "        Your job is to write a cold email to the client regarding the job mentioned above describing the capability of AtliQ \n",
    "        in fulfilling their needs.\n",
    "        Also add the most relevant ones from the following links to showcase Atliq's portfolio: {link_list}\n",
    "        Remember you are Mohan, BDE at AtliQ. \n",
    "        Do not provide a preamble.\n",
    "        ### EMAIL (NO PREAMBLE):\n",
    "        \n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "res = chain_email.invoke({\"job_description\": str(job), \"link_list\": links})\n",
    "print(res.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
